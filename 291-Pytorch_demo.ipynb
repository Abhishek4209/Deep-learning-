{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCvlYUCRkfMa"
      },
      "source": [
        "# PyTorch Basics: Tensors & Gradients\n",
        "\n",
        "<img src=\"data:image/png;base64,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\" width=\"600\"\n",
        "     height=\"300\">\n",
        "\n",
        "\n",
        "\n",
        "  PyTorch is an open-source machine learning framework that is primarily used for developing and training deep learning models. It was developed by Facebook's AI Research Lab and released in 2016. PyTorch provides a flexible and dynamic approach to building neural networks, making it a popular choice among researchers and developers.\n",
        "\n",
        "The framework is built on a dynamic computational graph concept, which means that the graph is built and modified on-the-fly as the program runs. This allows for more intuitive and flexible model development, as you can use standard Python control flow statements and debug the model easily.\n",
        "\n",
        "PyTorch supports automatic differentiation, which enables efficient computation of gradients for training neural networks using backpropagation. It provides a rich set of tools and libraries for tasks such as data loading, model building, optimization, and evaluation.\n",
        "\n",
        "One of the key advantages of PyTorch is its support for GPU acceleration, allowing you to train models on GPUs to significantly speed up computations. It also has a large and active community, which means there are plenty of resources, tutorials, and pre-trained models available.\n",
        "\n",
        "PyTorch is often compared to TensorFlow, another popular deep learning framework. While TensorFlow focuses more on static computation graphs, PyTorch emphasizes dynamic computation graphs. This fundamental difference in design philosophy gives PyTorch an edge when it comes to flexibility and ease of use.\n",
        "\n",
        "Overall, PyTorch is widely used in the research community and is gaining popularity in industry applications as well. It provides a powerful and user-friendly platform for building and training deep learning models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5zufMMCkfMo"
      },
      "source": [
        "## installation\n",
        "\n",
        "installation instructions here: https://pytorch.org ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "SmnQZPSxkfMp"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P18JcOiokfMr"
      },
      "source": [
        "Let's import the `torch` module to get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "DGo8nxo7kfMs"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqVgPkfKkfMt"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUtf5elpkfMv",
        "outputId": "c6213e23-bfa8-4898-94cd-7c22e0ac5e33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "execution_count": 235,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number\n",
        "t1 = torch.tensor(4.)\n",
        "t1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIB1GJlakfMw"
      },
      "source": [
        "`4.` is a shorthand for `4.0`. It is used to indicate to Python (and PyTorch) that you want to create a floating-point number. We can verify this by checking the `dtype` attribute of our tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz-QWm7NkfMx",
        "outputId": "0791321f-f126-429a-a9be-85df0cf7ce27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 236,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_-gGY-kfMy"
      },
      "source": [
        "Let's try creating more complex tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIn2pRzLkfMz",
        "outputId": "fa01602b-46be-48a7-d11a-be37901ecaf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vector\n",
        "t2 = torch.tensor([1., 2, 3, 4])\n",
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdQsBZqukfM0",
        "outputId": "b37bfbe3-504f-4cae-c872-2796ccf09cae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix\n",
        "t3 = torch.tensor([[5., 6],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "t3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yZHb2E5kfM0",
        "outputId": "1253aafb-43a5-40c2-f5ae-7660cec39235"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[11., 12., 13.],\n",
              "         [13., 14., 15.]],\n",
              "\n",
              "        [[15., 16., 17.],\n",
              "         [17., 18., 19.]]])"
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3-dimensional array\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13],\n",
        "     [13, 14, 15]],\n",
        "    [[15, 16, 17],\n",
        "     [17, 18, 19.]]])\n",
        "t4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS8_bliOkfM1"
      },
      "source": [
        "Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUx8_FbXkfM1",
        "outputId": "81fb8513-ad30-4f42-95a7-eb21bcea9db6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(t1)\n",
        "t1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeRzfymnkfM2",
        "outputId": "91f26c00-48c3-40b8-db6c-0580162c948b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3., 4.])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "execution_count": 241,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(t2)\n",
        "t2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXvIYzuxkfM2",
        "outputId": "6ca810a0-d20c-49f2-8a2c-363c5521f499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(t3)\n",
        "t3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5okplTtkfM3",
        "outputId": "6d16bb62-fe42-47d8-a26a-6324a2ecbb48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[11., 12., 13.],\n",
            "         [13., 14., 15.]],\n",
            "\n",
            "        [[15., 16., 17.],\n",
            "         [17., 18., 19.]]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(t4)\n",
        "t4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NOD0XtokfM3"
      },
      "source": [
        "Note that it's not possible to create tensors with an improper shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ZiaIlFtWkfM4",
        "outputId": "aba02c1a-bcd8-4536-cf47-ee7980aa61c5"
      },
      "outputs": [],
      "source": [
        "# # Matrix\n",
        "# t5 = torch.tensor([[5., 6, 11],\n",
        "#                 [7, 8],\n",
        "#                 [9, 10]])\n",
        "# t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWBdhA9kkfM4"
      },
      "source": [
        "A `ValueError` is thrown because the lengths of the rows `[5., 6, 11]` and `[7, 8]` don't match."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7cKJKdakfM5"
      },
      "source": [
        "## Tensor operations and gradients\n",
        "\n",
        "We can combine tensors with the usual arithmetic operations. Let's look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj6TfIlokfM5",
        "outputId": "628fca2f-675f-4c9a-d8a2-323ced3d93e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "execution_count": 245,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensors.\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "x, w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVZlcATrkfM5"
      },
      "source": [
        "We've created three tensors: `x`, `w`, and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment.\n",
        "\n",
        "Let's create a new tensor `y` by combining these tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKcsAaE0kfM6",
        "outputId": "d12880cc-a732-4b01-da26-c7e501796e99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Arithmetic operations\n",
        "y = w * x + b\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNV4U0-OkfM6"
      },
      "source": [
        "As expected, `y` is a tensor with the value `3 * 4 + 5 = 17`. What makes PyTorch unique is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. This feature of PyTorch is called _autograd_ (automatic gradients).\n",
        "\n",
        "To compute the derivatives, we can invoke the `.backward` method on our result `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "0RVH2vHCkfM6"
      },
      "outputs": [],
      "source": [
        "# Compute derivatives\n",
        "y.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHyHerbekfM7"
      },
      "source": [
        "The derivatives of `y` with respect to the input tensors are stored in the `.grad` property of the respective tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zTB-VUqkfM7",
        "outputId": "6d5d0032-6db9-4042-e8f3-c14e378bb704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# Display gradients\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvGfw6PJkfM7"
      },
      "source": [
        "As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`.\n",
        "\n",
        "The \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvR-LWzgkfM8"
      },
      "source": [
        "## Tensor functions\n",
        "\n",
        "Apart from arithmetic operations, the `torch` module also contains many functions for creating and manipulating tensors. Let's look at some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi5eISBckfM8",
        "outputId": "0de33509-4984-4d8f-c272-151695a9802f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "execution_count": 249,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor with a fixed value for every element\n",
        "t6 = torch.full((3, 2), 42)\n",
        "t6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caAPy-P7kfM8",
        "outputId": "679f1831-29ba-4dd0-c1e2-75f11b9fd0de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenate two tensors with compatible shapes\n",
        "t7 = torch.cat((t3, t6))\n",
        "t7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHmUkGOHkfM9",
        "outputId": "a21521d5-e61a-40d7-ca4c-9a41f18e473e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.6570,  0.9894],\n",
              "        [ 0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute the sin of each element\n",
        "t8 = torch.sin(t7)\n",
        "t8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9UFIgc-kfM9",
        "outputId": "ba505d7d-7c32-41fc-a7f5-8cb4b92ddf26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.6570,  0.9894]],\n",
              "\n",
              "        [[ 0.4121, -0.5440],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the shape of a tensor\n",
        "t9 = t8.reshape(3, 2, 2)\n",
        "t9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YK9aNsnkfM9"
      },
      "source": [
        "You can learn more about tensor operations here: https://pytorch.org/docs/stable/torch.html . Experiment with some more tensor functions and operations using the empty cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTgXrNyRkfM-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36942dZpkfM-"
      },
      "source": [
        "## Interoperability with Numpy\n",
        "\n",
        "[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
        "\n",
        "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
        "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
        "* [OpenCV](https://opencv.org/) for image and video processing\n",
        "\n",
        "\n",
        "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKH8QMxDkfM-"
      },
      "source": [
        "Here's how we create an array in Numpy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlCWcXUckfM_",
        "outputId": "ef6e6ad3-3fea-4e78-e5b3-d6c09cb58e7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1, 2], [3, 4.]])\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V-UeD40kfM_"
      },
      "source": [
        "We can convert a Numpy array to a PyTorch tensor using `torch.from_numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaPUjIiokfNB",
        "outputId": "c8ad3bb6-f60c-4af1-c7ef-035a52244434"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the numpy array to a torch tensor.\n",
        "y = torch.from_numpy(x)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-kN6vp4kfNC"
      },
      "source": [
        "Let's verify that the numpy array and torch tensor have similar data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL76Ma8ekfND",
        "outputId": "54ab5324-e79b-407b-b8c0-89ef879617df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.dtype, y.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-vuHKXXkfNE"
      },
      "source": [
        "We can convert a PyTorch tensor to a Numpy array using the `.numpy` method of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEBugCySkfNE",
        "outputId": "fb7b7496-d808-4d6f-8145-403652938ad7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert a torch tensor to a numpy array\n",
        "z = y.numpy()\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgxySGeWkfNE"
      },
      "source": [
        "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
        "\n",
        "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
        "\n",
        "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
        "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOg5UDH45k9x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPb963Lz5laq"
      },
      "source": [
        "## Linear-regression from scrach using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "elamAaJH5tYF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "Ze7LRltk5tUV"
      },
      "outputs": [],
      "source": [
        "#making training data\n",
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "ars5xesW5tRt"
      },
      "outputs": [],
      "source": [
        "# Targets (apples, oranges)\n",
        "target = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L92TqO635tPO",
        "outputId": "89e342c8-3939-4f44-8b67-6da057bfc0a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]) \n",
            "\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ],
      "source": [
        "#Convert input and target to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "target = torch.from_numpy(target)\n",
        "\n",
        "print(inputs,\"\\n\")\n",
        "print(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m_2iaph5tMh",
        "outputId": "9cef4156-01f7-4b8c-d157-cb8247a9b63d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4009, -0.0544,  0.0108],\n",
            "        [ 0.8357, -0.5979, -0.2274]], requires_grad=True)\n",
            "tensor([ 0.2382, -0.5217], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# weights and biases\n",
        "w = torch.randn(2,3 , requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "ZHqEIQKU56cs"
      },
      "outputs": [],
      "source": [
        "#define the model\n",
        "\n",
        "def model(x):\n",
        "  return x @ w.t() + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9J__d3l56Ze",
        "outputId": "eedb0f57-552b-4edf-948b-f349f8cff3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 26.3210,  10.6475],\n",
            "        [ 32.6207,   8.3591],\n",
            "        [ 28.4500, -21.1239],\n",
            "        [ 39.1875,  50.5975],\n",
            "        [ 23.4308, -16.1742]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# prediction\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV0XrG2k56Xf",
        "outputId": "b5b59959-16a2-40ca-8ac9-b1c201d3c221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ],
      "source": [
        "#actual\n",
        "print(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "vlr1NKsC56Ts"
      },
      "outputs": [],
      "source": [
        "# loss function MSE\n",
        "def MSE(actual, target):\n",
        "  diff = actual - target\n",
        "  return torch.sum(diff * diff) / diff.numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQJRKGXP56RJ",
        "outputId": "33cfbbd2-6a17-4145-d1da-1d716d48aa08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7236.3564, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# error\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "iGypGOsF56Oi"
      },
      "outputs": [],
      "source": [
        "# compute gradients\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKRT4IVP56Lu",
        "outputId": "283af31e-52dd-41e5-aec1-02336df2a05f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4009, -0.0544,  0.0108],\n",
            "        [ 0.8357, -0.5979, -0.2274]], requires_grad=True) \n",
            "\n",
            "tensor([[-3636.8179, -5055.8315, -2911.6565],\n",
            "        [-6822.3838, -9034.7314, -5275.8906]])\n"
          ]
        }
      ],
      "source": [
        "print(w, \"\\n\")\n",
        "print(w.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWMcsxjz6IBr",
        "outputId": "ba053027-5420-41f5-a75c-04b740ca68bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.2382, -0.5217], requires_grad=True) \n",
            "\n",
            "tensor([-46.1980, -85.5388])\n"
          ]
        }
      ],
      "source": [
        "print(b, \"\\n\")\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjdeYBsU6H-6",
        "outputId": "5832a926-e98c-4f5e-9e17-ad785eb8e0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ],
      "source": [
        "#reset grad\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIbBPr-x6H8l",
        "outputId": "f8974e80-681f-420e-8b9e-fcfe995ebedf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 26.3210,  10.6475],\n",
            "        [ 32.6207,   8.3591],\n",
            "        [ 28.4500, -21.1239],\n",
            "        [ 39.1875,  50.5975],\n",
            "        [ 23.4308, -16.1742]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# adjust params\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEOGA0cy6PzN",
        "outputId": "8635d910-3448-46ff-e47d-4a5154c0abab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7236.3564, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# loss\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du5TIt2e6Pwg",
        "outputId": "9704e23a-f37a-4137-a71e-37f673dca82d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-3636.8179, -5055.8315, -2911.6565],\n",
            "        [-6822.3838, -9034.7314, -5275.8906]]) \n",
            "\n",
            "tensor([-46.1980, -85.5388])\n"
          ]
        }
      ],
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad, \"\\n\")\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "Jx0SBLV56PtU"
      },
      "outputs": [],
      "source": [
        "  # adjust weight & reset grad\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD2CAdtn6Pq2",
        "outputId": "0568d999-f00f-4567-9c22-e71d7775fdf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4372, -0.0038,  0.0399],\n",
            "        [ 0.9039, -0.5076, -0.1746]], requires_grad=True)\n",
            "tensor([ 0.2387, -0.5209], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZT-GtGY6Xzq",
        "outputId": "e8246072-6438-42e2-fae8-119c729052ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5383.8428, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# calculate again\n",
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijRMFN3C6Xv1",
        "outputId": "dfe54b14-a643-4646-8046-c2147aea9e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs(0/100) & Loss 5383.8427734375\n",
            "Epochs(1/100) & Loss 4129.19189453125\n",
            "Epochs(2/100) & Loss 3277.509765625\n",
            "Epochs(3/100) & Loss 2697.46044921875\n",
            "Epochs(4/100) & Loss 2300.53955078125\n",
            "Epochs(5/100) & Loss 2027.099853515625\n",
            "Epochs(6/100) & Loss 1836.948486328125\n",
            "Epochs(7/100) & Loss 1702.997802734375\n",
            "Epochs(8/100) & Loss 1606.9931640625\n",
            "Epochs(9/100) & Loss 1536.6318359375\n",
            "Epochs(10/100) & Loss 1483.6224365234375\n",
            "Epochs(11/100) & Loss 1442.376953125\n",
            "Epochs(12/100) & Loss 1409.1282958984375\n",
            "Epochs(13/100) & Loss 1381.337158203125\n",
            "Epochs(14/100) & Loss 1357.291748046875\n",
            "Epochs(15/100) & Loss 1335.8370361328125\n",
            "Epochs(16/100) & Loss 1316.1943359375\n",
            "Epochs(17/100) & Loss 1297.8385009765625\n",
            "Epochs(18/100) & Loss 1280.4134521484375\n",
            "Epochs(19/100) & Loss 1263.679443359375\n",
            "Epochs(20/100) & Loss 1247.474365234375\n",
            "Epochs(21/100) & Loss 1231.687255859375\n",
            "Epochs(22/100) & Loss 1216.2431640625\n",
            "Epochs(23/100) & Loss 1201.090576171875\n",
            "Epochs(24/100) & Loss 1186.1943359375\n",
            "Epochs(25/100) & Loss 1171.529541015625\n",
            "Epochs(26/100) & Loss 1157.078857421875\n",
            "Epochs(27/100) & Loss 1142.830322265625\n",
            "Epochs(28/100) & Loss 1128.774169921875\n",
            "Epochs(29/100) & Loss 1114.904052734375\n",
            "Epochs(30/100) & Loss 1101.214599609375\n",
            "Epochs(31/100) & Loss 1087.701171875\n",
            "Epochs(32/100) & Loss 1074.360595703125\n",
            "Epochs(33/100) & Loss 1061.189453125\n",
            "Epochs(34/100) & Loss 1048.185302734375\n",
            "Epochs(35/100) & Loss 1035.345458984375\n",
            "Epochs(36/100) & Loss 1022.66748046875\n",
            "Epochs(37/100) & Loss 1010.1494140625\n",
            "Epochs(38/100) & Loss 997.7888793945312\n",
            "Epochs(39/100) & Loss 985.5838012695312\n",
            "Epochs(40/100) & Loss 973.5321044921875\n",
            "Epochs(41/100) & Loss 961.63232421875\n",
            "Epochs(42/100) & Loss 949.8820190429688\n",
            "Epochs(43/100) & Loss 938.2794189453125\n",
            "Epochs(44/100) & Loss 926.8226318359375\n",
            "Epochs(45/100) & Loss 915.5095825195312\n",
            "Epochs(46/100) & Loss 904.3390502929688\n",
            "Epochs(47/100) & Loss 893.30859375\n",
            "Epochs(48/100) & Loss 882.4169921875\n",
            "Epochs(49/100) & Loss 871.6617431640625\n",
            "Epochs(50/100) & Loss 861.0419921875\n",
            "Epochs(51/100) & Loss 850.5554809570312\n",
            "Epochs(52/100) & Loss 840.2008056640625\n",
            "Epochs(53/100) & Loss 829.97607421875\n",
            "Epochs(54/100) & Loss 819.8798828125\n",
            "Epochs(55/100) & Loss 809.91015625\n",
            "Epochs(56/100) & Loss 800.0659790039062\n",
            "Epochs(57/100) & Loss 790.3452758789062\n",
            "Epochs(58/100) & Loss 780.7463989257812\n",
            "Epochs(59/100) & Loss 771.2682495117188\n",
            "Epochs(60/100) & Loss 761.9091796875\n",
            "Epochs(61/100) & Loss 752.6673583984375\n",
            "Epochs(62/100) & Loss 743.5418701171875\n",
            "Epochs(63/100) & Loss 734.5306396484375\n",
            "Epochs(64/100) & Loss 725.6326904296875\n",
            "Epochs(65/100) & Loss 716.8461303710938\n",
            "Epochs(66/100) & Loss 708.1698608398438\n",
            "Epochs(67/100) & Loss 699.602783203125\n",
            "Epochs(68/100) & Loss 691.14306640625\n",
            "Epochs(69/100) & Loss 682.7894287109375\n",
            "Epochs(70/100) & Loss 674.54052734375\n",
            "Epochs(71/100) & Loss 666.395263671875\n",
            "Epochs(72/100) & Loss 658.3521728515625\n",
            "Epochs(73/100) & Loss 650.4097900390625\n",
            "Epochs(74/100) & Loss 642.5670166015625\n",
            "Epochs(75/100) & Loss 634.8226928710938\n",
            "Epochs(76/100) & Loss 627.1755981445312\n",
            "Epochs(77/100) & Loss 619.6243286132812\n",
            "Epochs(78/100) & Loss 612.1676025390625\n",
            "Epochs(79/100) & Loss 604.8045043945312\n",
            "Epochs(80/100) & Loss 597.5337524414062\n",
            "Epochs(81/100) & Loss 590.3539428710938\n",
            "Epochs(82/100) & Loss 583.2642822265625\n",
            "Epochs(83/100) & Loss 576.2634887695312\n",
            "Epochs(84/100) & Loss 569.3502807617188\n",
            "Epochs(85/100) & Loss 562.5238037109375\n",
            "Epochs(86/100) & Loss 555.78271484375\n",
            "Epochs(87/100) & Loss 549.1261596679688\n",
            "Epochs(88/100) & Loss 542.5532836914062\n",
            "Epochs(89/100) & Loss 536.0623779296875\n",
            "Epochs(90/100) & Loss 529.65283203125\n",
            "Epochs(91/100) & Loss 523.3236694335938\n",
            "Epochs(92/100) & Loss 517.07373046875\n",
            "Epochs(93/100) & Loss 510.902099609375\n",
            "Epochs(94/100) & Loss 504.8077087402344\n",
            "Epochs(95/100) & Loss 498.78955078125\n",
            "Epochs(96/100) & Loss 492.846923828125\n",
            "Epochs(97/100) & Loss 486.978515625\n",
            "Epochs(98/100) & Loss 481.18377685546875\n",
            "Epochs(99/100) & Loss 475.46124267578125\n",
            "Epochs(100/100) & Loss 469.810546875\n",
            "Epochs(101/100) & Loss 464.23040771484375\n",
            "Epochs(102/100) & Loss 458.72021484375\n",
            "Epochs(103/100) & Loss 453.2789001464844\n",
            "Epochs(104/100) & Loss 447.9056701660156\n",
            "Epochs(105/100) & Loss 442.5997009277344\n",
            "Epochs(106/100) & Loss 437.3600158691406\n",
            "Epochs(107/100) & Loss 432.1859436035156\n",
            "Epochs(108/100) & Loss 427.07635498046875\n",
            "Epochs(109/100) & Loss 422.03094482421875\n",
            "Epochs(110/100) & Loss 417.04840087890625\n",
            "Epochs(111/100) & Loss 412.128173828125\n",
            "Epochs(112/100) & Loss 407.26953125\n",
            "Epochs(113/100) & Loss 402.4715270996094\n",
            "Epochs(114/100) & Loss 397.73345947265625\n",
            "Epochs(115/100) & Loss 393.0546875\n",
            "Epochs(116/100) & Loss 388.4342346191406\n",
            "Epochs(117/100) & Loss 383.8716125488281\n",
            "Epochs(118/100) & Loss 379.36590576171875\n",
            "Epochs(119/100) & Loss 374.91656494140625\n",
            "Epochs(120/100) & Loss 370.522705078125\n",
            "Epochs(121/100) & Loss 366.1837463378906\n",
            "Epochs(122/100) & Loss 361.89892578125\n",
            "Epochs(123/100) & Loss 357.66766357421875\n",
            "Epochs(124/100) & Loss 353.4891052246094\n",
            "Epochs(125/100) & Loss 349.36273193359375\n",
            "Epochs(126/100) & Loss 345.28778076171875\n",
            "Epochs(127/100) & Loss 341.2637939453125\n",
            "Epochs(128/100) & Loss 337.2898864746094\n",
            "Epochs(129/100) & Loss 333.3655700683594\n",
            "Epochs(130/100) & Loss 329.4903259277344\n",
            "Epochs(131/100) & Loss 325.66339111328125\n",
            "Epochs(132/100) & Loss 321.884033203125\n",
            "Epochs(133/100) & Loss 318.15185546875\n",
            "Epochs(134/100) & Loss 314.466064453125\n",
            "Epochs(135/100) & Loss 310.82635498046875\n",
            "Epochs(136/100) & Loss 307.23193359375\n",
            "Epochs(137/100) & Loss 303.6824035644531\n",
            "Epochs(138/100) & Loss 300.1770324707031\n",
            "Epochs(139/100) & Loss 296.71533203125\n",
            "Epochs(140/100) & Loss 293.2967834472656\n",
            "Epochs(141/100) & Loss 289.92071533203125\n",
            "Epochs(142/100) & Loss 286.586669921875\n",
            "Epochs(143/100) & Loss 283.2941589355469\n",
            "Epochs(144/100) & Loss 280.042724609375\n",
            "Epochs(145/100) & Loss 276.83160400390625\n",
            "Epochs(146/100) & Loss 273.6605224609375\n",
            "Epochs(147/100) & Loss 270.52886962890625\n",
            "Epochs(148/100) & Loss 267.4361877441406\n",
            "Epochs(149/100) & Loss 264.3819274902344\n",
            "Epochs(150/100) & Loss 261.3656311035156\n",
            "Epochs(151/100) & Loss 258.38690185546875\n",
            "Epochs(152/100) & Loss 255.4451904296875\n",
            "Epochs(153/100) & Loss 252.5400390625\n",
            "Epochs(154/100) & Loss 249.6709442138672\n",
            "Epochs(155/100) & Loss 246.8374481201172\n",
            "Epochs(156/100) & Loss 244.0391845703125\n",
            "Epochs(157/100) & Loss 241.2757110595703\n",
            "Epochs(158/100) & Loss 238.546630859375\n",
            "Epochs(159/100) & Loss 235.85128784179688\n",
            "Epochs(160/100) & Loss 233.189453125\n",
            "Epochs(161/100) & Loss 230.5605926513672\n",
            "Epochs(162/100) & Loss 227.96444702148438\n",
            "Epochs(163/100) & Loss 225.40054321289062\n",
            "Epochs(164/100) & Loss 222.86831665039062\n",
            "Epochs(165/100) & Loss 220.36752319335938\n",
            "Epochs(166/100) & Loss 217.8977508544922\n",
            "Epochs(167/100) & Loss 215.4586181640625\n",
            "Epochs(168/100) & Loss 213.0496826171875\n",
            "Epochs(169/100) & Loss 210.6706085205078\n",
            "Epochs(170/100) & Loss 208.32101440429688\n",
            "Epochs(171/100) & Loss 206.0005340576172\n",
            "Epochs(172/100) & Loss 203.7087860107422\n",
            "Epochs(173/100) & Loss 201.44540405273438\n",
            "Epochs(174/100) & Loss 199.20994567871094\n",
            "Epochs(175/100) & Loss 197.00225830078125\n",
            "Epochs(176/100) & Loss 194.82186889648438\n",
            "Epochs(177/100) & Loss 192.66845703125\n",
            "Epochs(178/100) & Loss 190.5416259765625\n",
            "Epochs(179/100) & Loss 188.44117736816406\n",
            "Epochs(180/100) & Loss 186.3666534423828\n",
            "Epochs(181/100) & Loss 184.31781005859375\n",
            "Epochs(182/100) & Loss 182.29415893554688\n",
            "Epochs(183/100) & Loss 180.2955780029297\n",
            "Epochs(184/100) & Loss 178.32168579101562\n",
            "Epochs(185/100) & Loss 176.37216186523438\n",
            "Epochs(186/100) & Loss 174.44668579101562\n",
            "Epochs(187/100) & Loss 172.5450439453125\n",
            "Epochs(188/100) & Loss 170.66677856445312\n",
            "Epochs(189/100) & Loss 168.8117218017578\n",
            "Epochs(190/100) & Loss 166.9794921875\n",
            "Epochs(191/100) & Loss 165.16995239257812\n",
            "Epochs(192/100) & Loss 163.38265991210938\n",
            "Epochs(193/100) & Loss 161.6173858642578\n",
            "Epochs(194/100) & Loss 159.87387084960938\n",
            "Epochs(195/100) & Loss 158.15182495117188\n",
            "Epochs(196/100) & Loss 156.4510040283203\n",
            "Epochs(197/100) & Loss 154.7711181640625\n",
            "Epochs(198/100) & Loss 153.1118621826172\n",
            "Epochs(199/100) & Loss 151.47305297851562\n",
            "Epochs(200/100) & Loss 149.85438537597656\n",
            "Epochs(201/100) & Loss 148.25563049316406\n",
            "Epochs(202/100) & Loss 146.67652893066406\n",
            "Epochs(203/100) & Loss 145.11679077148438\n",
            "Epochs(204/100) & Loss 143.57632446289062\n",
            "Epochs(205/100) & Loss 142.0546875\n",
            "Epochs(206/100) & Loss 140.5517578125\n",
            "Epochs(207/100) & Loss 139.06729125976562\n",
            "Epochs(208/100) & Loss 137.6009979248047\n",
            "Epochs(209/100) & Loss 136.15272521972656\n",
            "Epochs(210/100) & Loss 134.7222442626953\n",
            "Epochs(211/100) & Loss 133.30917358398438\n",
            "Epochs(212/100) & Loss 131.91355895996094\n",
            "Epochs(213/100) & Loss 130.5349578857422\n",
            "Epochs(214/100) & Loss 129.1732635498047\n",
            "Epochs(215/100) & Loss 127.8282470703125\n",
            "Epochs(216/100) & Loss 126.4997329711914\n",
            "Epochs(217/100) & Loss 125.1873779296875\n",
            "Epochs(218/100) & Loss 123.89118957519531\n",
            "Epochs(219/100) & Loss 122.6107406616211\n",
            "Epochs(220/100) & Loss 121.3460693359375\n",
            "Epochs(221/100) & Loss 120.09672546386719\n",
            "Epochs(222/100) & Loss 118.8626708984375\n",
            "Epochs(223/100) & Loss 117.64372253417969\n",
            "Epochs(224/100) & Loss 116.4395980834961\n",
            "Epochs(225/100) & Loss 115.2502212524414\n",
            "Epochs(226/100) & Loss 114.07533264160156\n",
            "Epochs(227/100) & Loss 112.91475677490234\n",
            "Epochs(228/100) & Loss 111.76834869384766\n",
            "Epochs(229/100) & Loss 110.63591003417969\n",
            "Epochs(230/100) & Loss 109.51722717285156\n",
            "Epochs(231/100) & Loss 108.41217041015625\n",
            "Epochs(232/100) & Loss 107.32054138183594\n",
            "Epochs(233/100) & Loss 106.24223327636719\n",
            "Epochs(234/100) & Loss 105.17710876464844\n",
            "Epochs(235/100) & Loss 104.12481689453125\n",
            "Epochs(236/100) & Loss 103.08534240722656\n",
            "Epochs(237/100) & Loss 102.0584716796875\n",
            "Epochs(238/100) & Loss 101.04409790039062\n",
            "Epochs(239/100) & Loss 100.0420150756836\n",
            "Epochs(240/100) & Loss 99.05207824707031\n",
            "Epochs(241/100) & Loss 98.07417297363281\n",
            "Epochs(242/100) & Loss 97.10816955566406\n",
            "Epochs(243/100) & Loss 96.15376281738281\n",
            "Epochs(244/100) & Loss 95.2109603881836\n",
            "Epochs(245/100) & Loss 94.2795639038086\n",
            "Epochs(246/100) & Loss 93.35942077636719\n",
            "Epochs(247/100) & Loss 92.45040130615234\n",
            "Epochs(248/100) & Loss 91.55239868164062\n",
            "Epochs(249/100) & Loss 90.66525268554688\n",
            "Epochs(250/100) & Loss 89.78880310058594\n",
            "Epochs(251/100) & Loss 88.92292022705078\n",
            "Epochs(252/100) & Loss 88.0674819946289\n",
            "Epochs(253/100) & Loss 87.22235107421875\n",
            "Epochs(254/100) & Loss 86.38745880126953\n",
            "Epochs(255/100) & Loss 85.5625991821289\n",
            "Epochs(256/100) & Loss 84.74766540527344\n",
            "Epochs(257/100) & Loss 83.9425277709961\n",
            "Epochs(258/100) & Loss 83.14707946777344\n",
            "Epochs(259/100) & Loss 82.36114501953125\n",
            "Epochs(260/100) & Loss 81.584716796875\n",
            "Epochs(261/100) & Loss 80.817626953125\n",
            "Epochs(262/100) & Loss 80.05973815917969\n",
            "Epochs(263/100) & Loss 79.31087493896484\n",
            "Epochs(264/100) & Loss 78.5710678100586\n",
            "Epochs(265/100) & Loss 77.840087890625\n",
            "Epochs(266/100) & Loss 77.11785888671875\n",
            "Epochs(267/100) & Loss 76.40430450439453\n",
            "Epochs(268/100) & Loss 75.69923400878906\n",
            "Epochs(269/100) & Loss 75.00267791748047\n",
            "Epochs(270/100) & Loss 74.31436920166016\n",
            "Epochs(271/100) & Loss 73.6343002319336\n",
            "Epochs(272/100) & Loss 72.96238708496094\n",
            "Epochs(273/100) & Loss 72.29841613769531\n",
            "Epochs(274/100) & Loss 71.6424331665039\n",
            "Epochs(275/100) & Loss 70.99424743652344\n",
            "Epochs(276/100) & Loss 70.353759765625\n",
            "Epochs(277/100) & Loss 69.72090911865234\n",
            "Epochs(278/100) & Loss 69.0955581665039\n",
            "Epochs(279/100) & Loss 68.4776840209961\n",
            "Epochs(280/100) & Loss 67.86714172363281\n",
            "Epochs(281/100) & Loss 67.2638168334961\n",
            "Epochs(282/100) & Loss 66.66764831542969\n",
            "Epochs(283/100) & Loss 66.07861328125\n",
            "Epochs(284/100) & Loss 65.49649810791016\n",
            "Epochs(285/100) & Loss 64.92130279541016\n",
            "Epochs(286/100) & Loss 64.3528823852539\n",
            "Epochs(287/100) & Loss 63.791160583496094\n",
            "Epochs(288/100) & Loss 63.236122131347656\n",
            "Epochs(289/100) & Loss 62.687644958496094\n",
            "Epochs(290/100) & Loss 62.14558792114258\n",
            "Epochs(291/100) & Loss 61.6099739074707\n",
            "Epochs(292/100) & Loss 61.08066940307617\n",
            "Epochs(293/100) & Loss 60.55755615234375\n",
            "Epochs(294/100) & Loss 60.040611267089844\n",
            "Epochs(295/100) & Loss 59.529762268066406\n",
            "Epochs(296/100) & Loss 59.024879455566406\n",
            "Epochs(297/100) & Loss 58.52595901489258\n",
            "Epochs(298/100) & Loss 58.03290557861328\n",
            "Epochs(299/100) & Loss 57.54559326171875\n",
            "Epochs(300/100) & Loss 57.06397247314453\n",
            "Epochs(301/100) & Loss 56.588035583496094\n",
            "Epochs(302/100) & Loss 56.1176643371582\n",
            "Epochs(303/100) & Loss 55.6527214050293\n",
            "Epochs(304/100) & Loss 55.193267822265625\n",
            "Epochs(305/100) & Loss 54.739158630371094\n",
            "Epochs(306/100) & Loss 54.29033660888672\n",
            "Epochs(307/100) & Loss 53.84674072265625\n",
            "Epochs(308/100) & Loss 53.408355712890625\n",
            "Epochs(309/100) & Loss 52.975006103515625\n",
            "Epochs(310/100) & Loss 52.546730041503906\n",
            "Epochs(311/100) & Loss 52.1234016418457\n",
            "Epochs(312/100) & Loss 51.7049560546875\n",
            "Epochs(313/100) & Loss 51.2913932800293\n",
            "Epochs(314/100) & Loss 50.88262939453125\n",
            "Epochs(315/100) & Loss 50.47855758666992\n",
            "Epochs(316/100) & Loss 50.07917022705078\n",
            "Epochs(317/100) & Loss 49.684410095214844\n",
            "Epochs(318/100) & Loss 49.2942008972168\n",
            "Epochs(319/100) & Loss 48.908451080322266\n",
            "Epochs(320/100) & Loss 48.52721405029297\n",
            "Epochs(321/100) & Loss 48.15031814575195\n",
            "Epochs(322/100) & Loss 47.77773666381836\n",
            "Epochs(323/100) & Loss 47.409446716308594\n",
            "Epochs(324/100) & Loss 47.0454216003418\n",
            "Epochs(325/100) & Loss 46.685516357421875\n",
            "Epochs(326/100) & Loss 46.32977294921875\n",
            "Epochs(327/100) & Loss 45.978050231933594\n",
            "Epochs(328/100) & Loss 45.63035202026367\n",
            "Epochs(329/100) & Loss 45.286617279052734\n",
            "Epochs(330/100) & Loss 44.94685745239258\n",
            "Epochs(331/100) & Loss 44.61090850830078\n",
            "Epochs(332/100) & Loss 44.27880096435547\n",
            "Epochs(333/100) & Loss 43.95050048828125\n",
            "Epochs(334/100) & Loss 43.625892639160156\n",
            "Epochs(335/100) & Loss 43.3049430847168\n",
            "Epochs(336/100) & Loss 42.98766326904297\n",
            "Epochs(337/100) & Loss 42.67401123046875\n",
            "Epochs(338/100) & Loss 42.36380386352539\n",
            "Epochs(339/100) & Loss 42.057167053222656\n",
            "Epochs(340/100) & Loss 41.75398635864258\n",
            "Epochs(341/100) & Loss 41.45420455932617\n",
            "Epochs(342/100) & Loss 41.15778350830078\n",
            "Epochs(343/100) & Loss 40.86473846435547\n",
            "Epochs(344/100) & Loss 40.57489013671875\n",
            "Epochs(345/100) & Loss 40.28840255737305\n",
            "Epochs(346/100) & Loss 40.00505828857422\n",
            "Epochs(347/100) & Loss 39.72490310668945\n",
            "Epochs(348/100) & Loss 39.4478874206543\n",
            "Epochs(349/100) & Loss 39.17394256591797\n",
            "Epochs(350/100) & Loss 38.90309524536133\n",
            "Epochs(351/100) & Loss 38.635223388671875\n",
            "Epochs(352/100) & Loss 38.37029266357422\n",
            "Epochs(353/100) & Loss 38.10835647583008\n",
            "Epochs(354/100) & Loss 37.84933853149414\n",
            "Epochs(355/100) & Loss 37.5931396484375\n",
            "Epochs(356/100) & Loss 37.339805603027344\n",
            "Epochs(357/100) & Loss 37.0892333984375\n",
            "Epochs(358/100) & Loss 36.841468811035156\n",
            "Epochs(359/100) & Loss 36.596397399902344\n",
            "Epochs(360/100) & Loss 36.35405349731445\n",
            "Epochs(361/100) & Loss 36.1143684387207\n",
            "Epochs(362/100) & Loss 35.8773078918457\n",
            "Epochs(363/100) & Loss 35.642845153808594\n",
            "Epochs(364/100) & Loss 35.410911560058594\n",
            "Epochs(365/100) & Loss 35.18157196044922\n",
            "Epochs(366/100) & Loss 34.954673767089844\n",
            "Epochs(367/100) & Loss 34.73029327392578\n",
            "Epochs(368/100) & Loss 34.50830841064453\n",
            "Epochs(369/100) & Loss 34.28881072998047\n",
            "Epochs(370/100) & Loss 34.07162094116211\n",
            "Epochs(371/100) & Loss 33.85681915283203\n",
            "Epochs(372/100) & Loss 33.6442985534668\n",
            "Epochs(373/100) & Loss 33.434112548828125\n",
            "Epochs(374/100) & Loss 33.22620391845703\n",
            "Epochs(375/100) & Loss 33.020503997802734\n",
            "Epochs(376/100) & Loss 32.816993713378906\n",
            "Epochs(377/100) & Loss 32.61571502685547\n",
            "Epochs(378/100) & Loss 32.416568756103516\n",
            "Epochs(379/100) & Loss 32.219566345214844\n",
            "Epochs(380/100) & Loss 32.0246467590332\n",
            "Epochs(381/100) & Loss 31.831823348999023\n",
            "Epochs(382/100) & Loss 31.641000747680664\n",
            "Epochs(383/100) & Loss 31.452295303344727\n",
            "Epochs(384/100) & Loss 31.265527725219727\n",
            "Epochs(385/100) & Loss 31.080759048461914\n",
            "Epochs(386/100) & Loss 30.897933959960938\n",
            "Epochs(387/100) & Loss 30.717029571533203\n",
            "Epochs(388/100) & Loss 30.53804588317871\n",
            "Epochs(389/100) & Loss 30.360937118530273\n",
            "Epochs(390/100) & Loss 30.185720443725586\n",
            "Epochs(391/100) & Loss 30.012287139892578\n",
            "Epochs(392/100) & Loss 29.8407039642334\n",
            "Epochs(393/100) & Loss 29.6708927154541\n",
            "Epochs(394/100) & Loss 29.502864837646484\n",
            "Epochs(395/100) & Loss 29.336589813232422\n",
            "Epochs(396/100) & Loss 29.172012329101562\n",
            "Epochs(397/100) & Loss 29.00918960571289\n",
            "Epochs(398/100) & Loss 28.8480224609375\n",
            "Epochs(399/100) & Loss 28.68853759765625\n"
          ]
        }
      ],
      "source": [
        "# Training for multiple epochs\n",
        "for i in range(400):\n",
        "  preds = model(inputs)\n",
        "  loss = MSE(target, preds)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "     w -= w.grad * 1e-5 # learning rate\n",
        "     b -= b.grad * 1e-5\n",
        "     w.grad.zero_()\n",
        "     b.grad.zero_()\n",
        "  print(f\"Epochs({i}/{100}) & Loss {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rShT9Hmj6XtR",
        "outputId": "3a164ba1-0781-4951-fab8-71d084c1ba62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(28.5307, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cezq8zGu6Xqs",
        "outputId": "a4ef29e0-7465-4f20-cd21-ebe617907f6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.341409806588877"
            ]
          },
          "execution_count": 279,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvsKGPfB6XoH",
        "outputId": "31277d35-68f3-4cbe-e73a-74236e68641f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 58.2325,  71.8011],\n",
              "        [ 80.5951,  97.9246],\n",
              "        [120.6438, 136.8025],\n",
              "        [ 26.8216,  45.8194],\n",
              "        [ 95.8129, 109.1201]], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 280,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U8284MJ6p5w",
        "outputId": "53914aca-0249-46b1-a9a7-745fba07c1ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "execution_count": 281,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "3jkj32ag6p3H"
      },
      "outputs": [],
      "source": [
        "## You can see they are almost close earch other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHrHiAXZ6pzu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-OUXNOx3CPg"
      },
      "source": [
        "## Neural Network using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHo8uHimkfNH",
        "outputId": "f417eca2-1271-4725-d16c-b06daef05340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Nov 21 16:39:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 511.65       Driver Version: 511.65       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:02:00.0 Off |                  N/A |\n",
            "| N/A   43C    P8     4W /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# To check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "jv4zRj3u3LtI"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch.utils.model_zoo'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32md:\\PW-DATA SCIENCE\\Week-21\\291-Pytorch_demo.ipynb Cell 79\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y141sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y141sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y141sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m ToTensor, Lambda, Compose\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y141sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Abhi\\anaconda3\\Lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodulefinder\u001b[39;00m \u001b[39mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m \u001b[39mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Abhi\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_optical_flow\u001b[39;00m \u001b[39mimport\u001b[39;00m FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stereo_matching\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     CarlaStereo,\n\u001b[0;32m      4\u001b[0m     CREStereo,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     SintelStereo,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcaltech\u001b[39;00m \u001b[39mimport\u001b[39;00m Caltech101, Caltech256\n",
            "File \u001b[1;32mc:\\Users\\Abhi\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\_optical_flow.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m _read_png_16\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _read_pfm, verify_str_arg\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvision\u001b[39;00m \u001b[39mimport\u001b[39;00m VisionDataset\n\u001b[0;32m     17\u001b[0m T1 \u001b[39m=\u001b[39m Tuple[Image\u001b[39m.\u001b[39mImage, Image\u001b[39m.\u001b[39mImage, Optional[np\u001b[39m.\u001b[39mndarray], Optional[np\u001b[39m.\u001b[39mndarray]]\n",
            "File \u001b[1;32mc:\\Users\\Abhi\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\utils.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_zoo\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internally_replaced_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m _download_file_from_remote_location, _is_remote_location_available\n\u001b[0;32m     28\u001b[0m USER_AGENT \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpytorch/vision\u001b[39m\u001b[39m\"\u001b[39m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch.utils.model_zoo'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swc3R2Ki3OSI",
        "outputId": "084bc77d-4b4c-40ce-c74a-f139ec81d50b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'datasets' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\PW-DATA SCIENCE\\Week-21\\291-Pytorch_demo.ipynb Cell 80\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Download training data from open datasets.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m training_data \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mFashionMNIST(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     root\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     transform\u001b[39m=\u001b[39mToTensor(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Download test data from open datasets.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test_data \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mFashionMNIST(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     root\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     transform\u001b[39m=\u001b[39mToTensor(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PW-DATA%20SCIENCE/Week-21/291-Pytorch_demo.ipynb#Y142sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
            "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd71u_LZ3QMo",
        "outputId": "cadc622c-044e-4923-bc18-1e2b6e0c9ae2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z8xEoct3Taa",
        "outputId": "e5774145-9510-40d5-8322-7b24d74aab77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    # print(X)\n",
        "    # print(y)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx_2V-C83aUS",
        "outputId": "e0fde571-427a-4998-f6db-72467f034eab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueZJS_-L3VQ4",
        "outputId": "92675220-831c-40b1-aed1-44c1c7503842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SEEk4fz3ey2"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tryz3wtG3ewp"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1C_N3if3j-j"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UxIUc-Y3mSp",
        "outputId": "1803e0d5-a1d4-47a5-abe7-9328599609da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.316672  [    0/60000]\n",
            "loss: 2.299611  [ 6400/60000]\n",
            "loss: 2.276056  [12800/60000]\n",
            "loss: 2.267389  [19200/60000]\n",
            "loss: 2.250305  [25600/60000]\n",
            "loss: 2.210238  [32000/60000]\n",
            "loss: 2.231450  [38400/60000]\n",
            "loss: 2.190959  [44800/60000]\n",
            "loss: 2.200532  [51200/60000]\n",
            "loss: 2.153820  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 2.147636 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.171121  [    0/60000]\n",
            "loss: 2.154280  [ 6400/60000]\n",
            "loss: 2.090852  [12800/60000]\n",
            "loss: 2.105507  [19200/60000]\n",
            "loss: 2.051154  [25600/60000]\n",
            "loss: 1.985906  [32000/60000]\n",
            "loss: 2.021355  [38400/60000]\n",
            "loss: 1.935196  [44800/60000]\n",
            "loss: 1.952712  [51200/60000]\n",
            "loss: 1.864827  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 51.2%, Avg loss: 1.863941 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.910603  [    0/60000]\n",
            "loss: 1.873535  [ 6400/60000]\n",
            "loss: 1.752214  [12800/60000]\n",
            "loss: 1.789106  [19200/60000]\n",
            "loss: 1.676216  [25600/60000]\n",
            "loss: 1.630203  [32000/60000]\n",
            "loss: 1.652746  [38400/60000]\n",
            "loss: 1.553478  [44800/60000]\n",
            "loss: 1.586449  [51200/60000]\n",
            "loss: 1.473644  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.494110 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.571199  [    0/60000]\n",
            "loss: 1.534655  [ 6400/60000]\n",
            "loss: 1.384191  [12800/60000]\n",
            "loss: 1.451482  [19200/60000]\n",
            "loss: 1.334421  [25600/60000]\n",
            "loss: 1.332630  [32000/60000]\n",
            "loss: 1.344593  [38400/60000]\n",
            "loss: 1.269534  [44800/60000]\n",
            "loss: 1.310125  [51200/60000]\n",
            "loss: 1.211971  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 1.237874 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.320967  [    0/60000]\n",
            "loss: 1.302911  [ 6400/60000]\n",
            "loss: 1.136904  [12800/60000]\n",
            "loss: 1.240004  [19200/60000]\n",
            "loss: 1.119631  [25600/60000]\n",
            "loss: 1.143259  [32000/60000]\n",
            "loss: 1.161697  [38400/60000]\n",
            "loss: 1.096488  [44800/60000]\n",
            "loss: 1.141878  [51200/60000]\n",
            "loss: 1.062178  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.1%, Avg loss: 1.082332 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqdoWByK3oxh",
        "outputId": "f1255f2f-c5ad-4b1b-d64e-d21e91336804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "#save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB0EWHe24DXZ",
        "outputId": "b1cb826f-e321-4e10-f176-e761de2fc0ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load model\n",
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRHA5ZZP4HEJ",
        "outputId": "fffed502-2856-4b61-a768-0b60617527ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "## Prediction\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zvhooAy4KUJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
